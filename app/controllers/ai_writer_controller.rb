# frozen_string_literal: true

require 'openai'

# AiWriterController handles AI content generation and application.
class AiWriterController < ApplicationController
  before_action :find_project_and_authorize
  before_action :find_issue, only: [:generate_content, :apply_content]
  before_action :find_content, only: [:apply_content, :update_content]

  # Generates content via OpenAI API, using project-specific memories.
  def generate_content
    settings = Setting.plugin_redmine_ai_writer
    api_key = settings['openai_api_key']
    prompt_cf_id = settings['prompt_custom_field_id']&.to_i

    if api_key.blank?
      return render json: { error: l(:error_ai_writer_api_key_not_set) }, status: :unprocessable_entity
    end

    if prompt_cf_id.blank? || prompt_cf_id <= 0
      return render json: { error: l(:error_ai_writer_prompt_cf_not_set) }, status: :unprocessable_entity
    end

    user_prompt = @issue.custom_value_for(prompt_cf_id)&.value
    if user_prompt.blank?
      return render json: { error: l(:error_ai_writer_prompt_is_empty) }, status: :unprocessable_entity
    end

    begin
      client = OpenAI::Client.new(access_token: api_key)
      response = client.chat(parameters: build_chat_parameters(user_prompt))
      generated_text = response.dig("choices", 0, "message", "content")

      if generated_text.present?
        content = AiWriterContent.create!(
          issue: @issue,
          author: User.current,
          user_prompt: user_prompt, # Use the prompt from the custom field
          system_prompt: settings['system_prompt'],
          generated_content: generated_text
        )
        render json: { content: content.generated_content, content_id: content.id }
      else
        raise "No content was generated by the AI."
      end

    rescue => e
      logger.error("AI Writer Plugin: Error during API call - #{e.message}\n#{e.backtrace.join("\n")}")
      render json: { error: l(:error_ai_writer_generation_failed, error_message: e.message) }, status: :internal_server_error
    end
  end

  # Applies the selected AI-generated content to the issue's description.
  def apply_content
    ActiveRecord::Base.transaction do
      @issue.update!(description: @content.generated_content)
      @content.update!(status: :applied)
    end

    render json: { success: true, message: l(:notice_successful_update) }
  rescue ActiveRecord::RecordInvalid => e
    render json: { success: false, error: e.record.errors.full_messages.join(', ') }, status: :unprocessable_entity
  end

  # Updates the content of an AI writer record after user edits.
  def update_content
    if @content.update(generated_content: params[:content])
      render json: { success: true, message: l(:notice_successful_update) }
    else
      render json: { success: false, error: @content.errors.full_messages.join(', ') }, status: :unprocessable_entity
    end
  end

  private

  # Finds the correct project context based on the action and authorizes the user.
  def find_project_and_authorize
    case params[:action].to_sym
    when :update_content
      @content = AiWriterContent.find(params[:content_id])
      @project = @content.issue.project
    when :generate_content, :apply_content
      @issue = Issue.find(params[:issue_id])
      @project = @issue.project
    end
    authorize
  rescue ActiveRecord::RecordNotFound
    render_404
  rescue Redmine::AccessDenied
    render_403
  end

  def find_issue
    @issue ||= Issue.find(params[:issue_id])
  end

  def find_content
    @content ||= AiWriterContent.find(params[:content_id])
  end

  def build_chat_parameters(user_prompt)
    settings = Setting.plugin_redmine_ai_writer
    # Retrieve only the latest approved (applied) memories for the current issue
    memories = AiWriterContent.applied.where(issue_id: @project.issues.select(:id)).order(updated_at: :desc).limit(5)
    
    model_name = settings['openai_model'].presence || 'gpt-3.5-turbo'
    temperature_value = settings['temperature'].presence || '0.7'
    temperature_value = temperature_value.to_f
    
    {
      model: model_name,
      messages: build_messages(settings['system_prompt'], user_prompt, memories),
      temperature: temperature_value
    }
  end

  def build_messages(system_prompt, user_prompt, memories)
    messages = [{ role: "system", content: system_prompt }]
    
    # Add historical data as context
    memories.reverse_each do |memory|
      messages << { role: "user", content: memory.user_prompt }
      messages << { role: "assistant", content: memory.generated_content }
    end

    # Add the current request
    messages << { role: "user", content: user_prompt }
    messages
  end
end
